{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "from pygame import mixer\n",
    "import tempfile\n",
    "from gtts import gTTS\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "url = \"http://192.168.0.224:80\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算角度的副函式\n",
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    # 獲取所需座標\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "    # 計算三點之間的夾角\n",
    "    angle = math.floor(math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2)))\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    if angle>180:\n",
    "        angle=360-angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to Speech\n",
    "def speak(sentence, lang):\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as fp:\n",
    "        tts=gTTS(text=sentence, lang=lang)\n",
    "        tts.save('{}.mp3'.format(fp.name))\n",
    "        mixer.init()\n",
    "        mixer.music.load('{}.mp3'.format(fp.name))\n",
    "        mixer.music.play(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) \n",
    "    height, width, _ = image.shape\n",
    "    landmarks = []\n",
    "    if results.pose_landmarks:\n",
    "            # 畫關鍵點在圖片上\n",
    "        mp_drawing.draw_landmarks(image=image, landmark_list=results.pose_landmarks,\n",
    "                    connections=mp_pose.POSE_CONNECTIONS)\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "        # 將關鍵點加進list內.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                    (landmark.z * width)))    \n",
    "    try:\n",
    "        l_elbow = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    except:\n",
    "        l_elbow=0\n",
    "    try:\n",
    "        # 取得右肩、右肘和右腕之間的夾角。    # 12 14 16 \n",
    "        r_elbow = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "    except:\n",
    "        r_elbow=0\n",
    "    try:\n",
    "        # 取得左肘、左肩和左臀之間的夾角。    # 13 11 23\n",
    "        l_shoulder = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "    except:\n",
    "        l_shoulder=0\n",
    "    try:\n",
    "        # 取得右臀、右肩和右肘之間的夾角。    # 14 12 24\n",
    "        r_shoulder = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "    except:\n",
    "        r_shoulder=0\n",
    "    try: # 左臀角度 \n",
    "        l_hip = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value])       \n",
    "    except:\n",
    "        l_hip=0\n",
    "    try: # 右臀角度\n",
    "        r_hip = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value])           \n",
    "    except:\n",
    "        r_hip=0\n",
    "    try:\n",
    "        # 取得左臀、左膝蓋和左腳踝之間的角度。# 23 25 27\n",
    "        l_knee = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    except:\n",
    "        l_knee=0        \n",
    "    try:\n",
    "        # 取得右臀、右膝蓋和右腳踝之間的角度。# 24 26 28 \n",
    "        r_knee = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    except:\n",
    "        r_knee=0\n",
    "    \n",
    "    return landmarks,image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#嬰兒式\n",
    "def ep4_baby1():\n",
    "    lastTime1 = time()\n",
    "    lastTime2 = time()\n",
    "    lastTime3 = time()\n",
    "    lastTime4 = time()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                      min_detection_confidence=0.5,\n",
    "                      min_tracking_confidence=0.5, \n",
    "                      model_complexity=2)as pose:\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            # Make detection\n",
    "            output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee=mediapipe_detection(frame, pose)\n",
    "          \n",
    "            condA = l_knee>50 or r_knee>50\n",
    "            condB = l_shoulder<150 or r_shoulder<150    \n",
    "            condC = l_hip>70 or r_hip>70\n",
    "\n",
    "            if condA and (time()-lastTime1)<3:\n",
    "                text1= 'hip back on heel'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                # lastTime = time()\n",
    "            elif condA and (time()-lastTime1)>3 :\n",
    "                text1= 'hip back on heel'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                lastTime1 = time()\n",
    "                speak(\"臀往後坐在腳跟上\",'zh-tw')\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<3:\n",
    "                    text2= 'hands straight forward'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>3:\n",
    "                    speak(\"雙手伸直往前延伸\",'zh-tw')\n",
    "                    text2= 'hands straight forward'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    lastTime2 = time()\n",
    "                else:\n",
    "                    text2= ' '\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    if condC and (time()-lastTime3)<3:\n",
    "                        text3= 'hip back on heel 2'\n",
    "                        cv2.putText(output_image, text3, (30, 90),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)    \n",
    "                    elif condC and (time()-lastTime3)>3:\n",
    "                        speak(\"臀往後坐在腳跟上\",'zh-tw')\n",
    "                        text3= 'hip back on heel 2'\n",
    "                        cv2.putText(output_image, text3, (30, 90),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        lastTime3 = time()\n",
    "                    elif (time()-lastTime4)>3:\n",
    "                        text3= ' success '\n",
    "                        speak(\"完美!\",'zh-tw')\n",
    "                        cv2.putText(output_image, text3, (30, 90),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        lastTime4 = time()\n",
    "                        break\n",
    "\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#測試雙手伸直\n",
    "def test_hand():\n",
    "    lastTime1 = time()\n",
    "    lastTime2 = time()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                      min_detection_confidence=0.5,\n",
    "                      min_tracking_confidence=0.5, \n",
    "                      model_complexity=2)as pose:\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_elbow<140 \n",
    "            condB = r_elbow<140   \n",
    "             \n",
    "            if condA and (time()-lastTime1)<3:\n",
    "                text1= 'left hand stright'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>3 :\n",
    "                text1= 'left hand stright'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                lastTime1 = time()\n",
    "                speak(\"左手打平\",'zh-tw')\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<3 :\n",
    "                    text2= 'right hand straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>3 :\n",
    "                    speak(\"右手打平\",'zh-tw')\n",
    "                    text2= 'right hand straight'\n",
    "                    lastTime2 = time()\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                else:\n",
    "                    text2= ' success '\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "        \n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_up():\n",
    "    lastTime1 = time()\n",
    "    lastTime2 = time()\n",
    "    lastTime3 = time()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                      min_detection_confidence=0.5,\n",
    "                      min_tracking_confidence=0.5, \n",
    "                      model_complexity=2)as pose:\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_hip<165 or r_hip<165\n",
    "            condB = l_knee<165 or r_knee<165\n",
    "            condC = l_shoulder<165 or r_shoulder<165\n",
    "             \n",
    "            if condA and (time()-lastTime1)<3:\n",
    "                text1= 'standing move'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>3 :\n",
    "                text1= 'standing move'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                lastTime1 = time()\n",
    "                speak(\"請保持站姿\",'zh-tw')\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<3 :\n",
    "                    text2= 'standing move'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>3 :\n",
    "                    speak(\"請保持站姿\",'zh-tw')\n",
    "                    text2='standing move'\n",
    "                    lastTime2 = time()\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                else:\n",
    "                    text2= ' '\n",
    "                    cv2.putText(output_image, text2, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    if condC and (time()-lastTime3)<3 :\n",
    "                        text3= 'hands over head'\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    elif condB and (time()-lastTime3)>3 :\n",
    "                        speak(\"雙手高舉過頭\",'zh-tw')\n",
    "                        text3='hands over head'\n",
    "                        lastTime3 = time()\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    else:\n",
    "                        text3= ' success '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "        \n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 2 前彎向下\n",
    "def pose2():\n",
    "    lastTime1 = time()\n",
    "    lastTime2 = time()\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5) # 發送 GET 請求\n",
    "        if response.status_code == 200:\n",
    "            print(\"伺服器運作正常\")\n",
    "        else:\n",
    "            print(f\"伺服器回傳了錯誤的狀態碼: {response.status_code}\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(requests.exceptions.ConnectionError)\n",
    "        \n",
    "    cap = cv2.VideoCapture(\"yoga-1.mp4\")  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        # speak(\"待會要做前彎向下,請注意平衡安全__  \",'zh-tw')   \n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA =l_hip>40 or r_hip>40\n",
    "            condB = l_knee<150 or r_knee<150\n",
    "                \n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'upper body close to thigh'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'upper body close to thigh'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"上身貼近大腿\",'zh-tw')\n",
    "                lastTime1 = time()\n",
    "                if(requests.exceptions.ConnectionError):\n",
    "                    pass\n",
    "                else:\n",
    "                    data = {'shoulder': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                \n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'keep your legs straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'keep your legs straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"雙腿盡量伸直\",'zh-tw')\n",
    "                    lastTime2 = time() \n",
    "                    if(requests.exceptions.ConnectionError):\n",
    "                        pass\n",
    "                    else:\n",
    "                        data = {'knee': '1'}\n",
    "                        response = requests.post(url, data=data)\n",
    "                        print(response.text)\n",
    "                                       \n",
    "                else:\n",
    "                    text2= ' success '\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    return\n",
    "            color=(0,0,255)\n",
    "                    \n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_elbow),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_elbow),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_shoulder),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_shoulder),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_hip),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_hip),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_knee),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_knee),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 3 背部向前延伸\n",
    "def pose3():\n",
    "    lastTime1 = time()\n",
    "    lastTime2 = time()\n",
    "    cap = cv2.VideoCapture(\"yoga-1.mp4\")  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        # speak(\"待會要做前彎向下,請注意平衡安全__  \",'zh-tw')   \n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA =l_hip<50 or r_hip<50\n",
    "            condB = l_knee<160 or r_knee<160\n",
    "                \n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'back forward'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'back forward'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"上身抬高,背部向前延伸\",'zh-tw')\n",
    "                data = {'shoulder': '1'}\n",
    "                response = requests.post(url, data=data)\n",
    "                print(response.text)\n",
    "                lastTime1 = time()\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'keep your legs straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'keep your legs straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"雙腿盡量伸直\",'zh-tw')\n",
    "                    data = {'knee': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                    lastTime2 = time() \n",
    "                else:\n",
    "                    text2= ' success '\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            color=(0,0,255)\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_elbow),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_elbow),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_shoulder),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_shoulder),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_hip),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_hip),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_knee),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_knee),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 4 下犬式\n",
    "def pose4():\n",
    "    lastTime1 = time()\n",
    "    lastTime2 = time()\n",
    "    cap = cv2.VideoCapture(\"yoga-1.mp4\")  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_knee<150 or r_knee<150\n",
    "            condB = l_shoulder<150 or r_shoulder<150   \n",
    "                    \n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'legs straight'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'legs straight'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"雙腳伸直\",'zh-tw')\n",
    "                data = {'knee': '1'}\n",
    "                response = requests.post(url, data=data)\n",
    "                print(response.text)\n",
    "                lastTime1 = time()\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'shoulder and back straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'shoulder and back straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"肩膀與背部打直\",'zh-tw')\n",
    "                    data = {'shoulder': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                    lastTime2 = time() \n",
    "                else:\n",
    "                    text2= ' success '\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            color=(0,0,255)\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_elbow),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_elbow),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_shoulder),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_shoulder),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_hip),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_hip),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_knee),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_knee),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 5 平板式\n",
    "def pose5():\n",
    "    lastTime1 = time()\n",
    "    lastTime2 = time()\n",
    "    lastTime3 = time()\n",
    "\n",
    "    cap = cv2.VideoCapture(\"yoga-1.mp4\")  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_shoulder>100 or r_shoulder>100\n",
    "            condB = l_knee <150 or r_knee <150  \n",
    "            condC = l_hip <150 or r_hip <150  \n",
    "\n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'Shoulders come directly over wrists'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'Shoulders come directly over wrists'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"肩膀來到手腕的正上方\",'zh-tw')\n",
    "                data = {'shoulder': '1'}\n",
    "                response = requests.post(url, data=data)\n",
    "                print(response.text)\n",
    "                lastTime1 = time()\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'hip and leg straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'ship and leg straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"膝蓋打直\",'zh-tw')\n",
    "                    data = {'knee': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                    lastTime2 = time() \n",
    "                else:\n",
    "                    text2= ' '\n",
    "                    cv2.putText(output_image, text2, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    if condC and (time()-lastTime3)<4 :\n",
    "                        text3= 'hip straight'\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    elif condC and (time()-lastTime3)>=4 :\n",
    "                        text3= 'hip straight'\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        speak(\"臀部打平\",'zh-tw')\n",
    "                        data = {'hip':'1'}\n",
    "                        response = requests.post(url, data=data)\n",
    "                        print(response.text)\n",
    "                        lastTime3 = time() \n",
    "                    else:\n",
    "                        text3= ' success '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    \n",
    "\n",
    "            color=(0,0,255)\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_elbow),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_elbow),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_shoulder),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_shoulder),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_hip),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_hip),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_knee),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_knee),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 6 眼鏡蛇式\n",
    "def pose6():\n",
    "    lastTime1 = time()\n",
    "    lastTime2 = time()\n",
    "    lastTime3 = time()\n",
    "\n",
    "    cap = cv2.VideoCapture(\"yoga-1.mp4\")  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_knee<160 or r_knee<160\n",
    "            condB = l_hip >150 or r_hip >150\n",
    "            condC = l_shoulder>30 or r_shoulder>30\n",
    "\n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'straight the legs'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'straight the legs'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"雙腿伸直\",'zh-tw')\n",
    "                data = {'knee':'1'}\n",
    "                response = requests.post(url, data=data)\n",
    "                print(response.text)\n",
    "                lastTime1 = time()\n",
    "            else:\n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'low-body on the floor'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'low-body on the floor'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"下半身貼好在地板上\",'zh-tw')\n",
    "                    data = {'hip':'1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                    lastTime2= time() \n",
    "                else:    \n",
    "                    text2= ' '\n",
    "                    cv2.putText(output_image, text2, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    if condB and (time()-lastTime3)<4 :\n",
    "                        text3= 'upper body improvement '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    elif condB and (time()-lastTime3)>=4 :\n",
    "                        text3= 'upper body improvement '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        speak(\"上半身提高\",'zh-tw')\n",
    "                        data = {'shoulder':'1'}\n",
    "                        response = requests.post(url, data=data)\n",
    "                        print(response.text)\n",
    "                        lastTime3 = time() \n",
    "                    else:\n",
    "                        text3= ' success '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            color=(0,0,255)\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_elbow),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_elbow),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_shoulder),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_shoulder),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_hip),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_HIP.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_hip),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            # try:\n",
    "            #     cv2.putText(\n",
    "            #             output_image,\n",
    "            #             str(l_knee),\n",
    "            #             (\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][0],\n",
    "            #                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value][1],\n",
    "            #             ),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #             1,color,2,cv2.LINE_AA,)\n",
    "            # except:\n",
    "            #     pass\n",
    "            try:\n",
    "                cv2.putText(\n",
    "                        output_image,\n",
    "                        str(r_knee),\n",
    "                        (\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],\n",
    "                        ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.exceptions.ConnectionError'>\n",
      "<class 'requests.exceptions.ConnectionError'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mtimeout\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m pygame\u001b[39m.\u001b[39mtime\u001b[39m.\u001b[39mwait(\u001b[39m3000\u001b[39m) \u001b[39m#34s\u001b[39;00m\n\u001b[0;32m     27\u001b[0m pygame\u001b[39m.\u001b[39mmixer\u001b[39m.\u001b[39mmusic\u001b[39m.\u001b[39mpause()\n\u001b[1;32m---> 28\u001b[0m pose2()\n\u001b[0;32m     29\u001b[0m \u001b[39m## pose3\u001b[39;00m\n\u001b[0;32m     30\u001b[0m pygame\u001b[39m.\u001b[39mmixer\u001b[39m.\u001b[39mmusic\u001b[39m.\u001b[39mplay()\n",
      "Cell \u001b[1;32mIn[55], line 6\u001b[0m, in \u001b[0;36mpose2\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m lastTime2 \u001b[39m=\u001b[39m time()\n\u001b[0;32m      5\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, timeout\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m) \u001b[39m# 發送 GET 請求\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m      8\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m伺服器運作正常\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m         )\n\u001b[0;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    396\u001b[0m         conn\u001b[39m.\u001b[39mrequest_chunked(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[0;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBrokenPipeError\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\urllib3\\connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (six\u001b[39m.\u001b[39mensure_str(k\u001b[39m.\u001b[39mlower()) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m headers):\n\u001b[0;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[0;32m   1254\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   1255\u001b[0m     \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(body, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1299\u001b[0m     \u001b[39m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m     \u001b[39m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1250\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1009\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer)\n\u001b[0;32m   1010\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1013\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(message_body, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1017\u001b[0m         \u001b[39m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m         \u001b[39m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m         \u001b[39m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    950\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    952\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m     extra_kw[\u001b[39m\"\u001b[39m\u001b[39msocket_options\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket_options\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m    179\u001b[0m     \u001b[39mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    180\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConnection to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m timed out. (connect timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout),\n\u001b[0;32m    183\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jackl\\Anaconda3\\envs\\testAI\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m source_address:\n\u001b[0;32m     84\u001b[0m         sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m     sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m sock\n\u001b[0;32m     88\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "pygame.init()\n",
    "\n",
    "# 播放 MP3 音檔\n",
    "pygame.mixer.music.load('EP18.mp3')\n",
    "pygame.mixer.music.play()\n",
    "\n",
    "## 開頭\n",
    "# pygame.mixer.music.set_pos(380) # 6:20\n",
    "# pygame.time.wait(27000) #26s\n",
    "# pygame.mixer.music.pause()\n",
    "## pose2\n",
    "pygame.mixer.music.unpause()\n",
    "pygame.mixer.music.set_pos(407) # 6:46\n",
    "pygame.time.wait(3000) #34s\n",
    "pygame.mixer.music.pause()\n",
    "pose2()\n",
    "## pose3\n",
    "pygame.mixer.music.play()\n",
    "pygame.mixer.music.set_pos(440) # 7:20\n",
    "pygame.time.wait(9000) #9s\n",
    "pygame.mixer.music.pause()\n",
    "## pose4\n",
    "# pygame.mixer.music.set_pos(449) # 7:29\n",
    "# pygame.time.wait(43000) #43s\n",
    "# pygame.mixer.music.pause()\n",
    "## pose5\n",
    "# pygame.mixer.music.set_pos(492) # 8:12\n",
    "# pygame.time.wait(7000) #7s\n",
    "# pygame.mixer.music.pause()\n",
    "## 過渡\n",
    "# pygame.mixer.music.set_pos(499) # 8:19\n",
    "# pygame.time.wait(19500) #19.5s\n",
    "# pygame.mixer.music.pause()\n",
    "## pose6\n",
    "# pygame.mixer.music.set_pos(518) # 7:29\n",
    "# pygame.time.wait(16000) #10s\n",
    "# pygame.mixer.music.pause()\n",
    "## pose4\n",
    "# pygame.mixer.music.set_pos(534) # 7:29\n",
    "# pygame.time.wait(19000) #10s\n",
    "# pygame.mixer.music.pause()\n",
    "## pose2\n",
    "# pygame.mixer.music.set_pos(553) # 7:29\n",
    "# pygame.time.wait(20500) #10s\n",
    "# pygame.mixer.music.pause()\n",
    "\n",
    "# # 繼續播放 MP3 音檔\n",
    "# pygame.mixer.music.unpause()\n",
    "\n",
    "# # 停止 MP3 音檔\n",
    "# pygame.mixer.music.stop()\n",
    "\n",
    "    \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82a87e48d8ad47d54d8434aa198ab5f7e9ca4eddc7a6e80c14d429723cf302a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
