{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.0.22, Python 3.8.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "from pygame import mixer\n",
    "import tempfile\n",
    "from gtts import gTTS\n",
    "import requests\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# url = \"http://192.168.0.118:80\" #cilab\n",
    "url = \"http://172.20.10.12:80\" #phone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算角度的副函式\n",
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    # 獲取所需座標\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "    # 計算三點之間的夾角\n",
    "    angle = math.floor(math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2)))\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    if angle>180:\n",
    "        angle=360-angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculatey(landmark1, landmark2):\n",
    "#     # 獲取所需座標\n",
    "#     x1, y1, _ = landmark1\n",
    "#     x2, y2, _ = landmark2\n",
    "\n",
    "#     y= abs(math.floor(y1 - y2))\n",
    "\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算角度的副函式\n",
    "def calculatexang(landmark1, landmark2):\n",
    "    # 獲取所需座標\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "\n",
    "    angle=math.floor(math.degrees(math.atan2(y1 - y2, x1 - x2)))\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    if angle>180:\n",
    "        angle=360-angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to Speech\n",
    "def speak(sentence, lang):\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as fp:\n",
    "        tts=gTTS(text=sentence, lang=lang)\n",
    "        tts.save('{}.mp3'.format(fp.name))\n",
    "        mixer.init()\n",
    "        mixer.music.load('{}.mp3'.format(fp.name))\n",
    "        mixer.music.play(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) \n",
    "    height, width, _ = image.shape\n",
    "    landmarks = []\n",
    "    if results.pose_landmarks:\n",
    "            # 畫關鍵點在圖片上\n",
    "        mp_drawing.draw_landmarks(image=image, landmark_list=results.pose_landmarks,\n",
    "                    connections=mp_pose.POSE_CONNECTIONS)\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "        # 將關鍵點加進list內.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                    (landmark.z * width)))    \n",
    "    try:\n",
    "        l_elbow = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    except:\n",
    "        l_elbow=0\n",
    "    try:\n",
    "        # 取得右肩、右肘和右腕之間的夾角。    # 12 14 16 \n",
    "        r_elbow = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "    except:\n",
    "        r_elbow=0\n",
    "    try:\n",
    "        # 取得左肘、左肩和左臀之間的夾角。    # 13 11 23\n",
    "        l_shoulder = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "    except:\n",
    "        l_shoulder=0\n",
    "    try:\n",
    "        # 取得右臀、右肩和右肘之間的夾角。    # 14 12 24\n",
    "        r_shoulder = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "    except:\n",
    "        r_shoulder=0\n",
    "    try: # 左臀角度 \n",
    "        l_hip = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value])       \n",
    "    except:\n",
    "        l_hip=0\n",
    "    try: # 右臀角度\n",
    "        r_hip = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value])           \n",
    "    except:\n",
    "        r_hip=0\n",
    "    try:\n",
    "        # 取得左臀、左膝蓋和左腳踝之間的角度。# 23 25 27\n",
    "        l_knee = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    except:\n",
    "        l_knee=0        \n",
    "    try:\n",
    "        # 取得右臀、右膝蓋和右腳踝之間的角度。# 24 26 28 \n",
    "        r_knee = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    except:\n",
    "        r_knee=0\n",
    "    try:\n",
    "        # 取得左臀、左膝蓋和左腳踝之間的角度。# 23 25 27\n",
    "        l_knee2ankle = calculatexang( landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    except:\n",
    "        l_knee2ankle=0        \n",
    "    try:\n",
    "        # 取得右臀、右膝蓋和右腳踝之間的角度。# 24 26 28 \n",
    "        r_knee2ankle = calculatexang( landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    except:\n",
    "        r_knee2ankle=0\n",
    "    return landmarks,image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee,l_knee2ankle,r_knee2ankle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_http():\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5) # 發送 GET 請求\n",
    "        if response.status_code == 200:\n",
    "            x=1\n",
    "            print(\"伺服器運作正常\")\n",
    "            return x\n",
    "        else:\n",
    "            print(f\"伺服器回傳了錯誤的狀態碼: {response.status_code}\")\n",
    "            x=0\n",
    "            return x\n",
    "    except :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def touch(mp3name):\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(mp3name)\n",
    "        # 如果按下 q 鍵，就停止處理影像\n",
    "    pygame.mixer.music.play()\n",
    "    while mixer.music.get_busy() == True:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            pygame.mixer.music.stop()\n",
    "        # cv2.destroyAllWindows()    \n",
    "    # 停止播放音樂\n",
    "    pygame.mixer.music.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mp3name,cap):\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(mp3name)\n",
    "    \n",
    "\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                        min_detection_confidence=0.5,\n",
    "                        min_tracking_confidence=0.5, \n",
    "                        model_complexity=0)as pose:\n",
    "    # 處理攝像頭影像\n",
    "        while cap.isOpened():\n",
    "        # while ret:\n",
    "            pygame.mixer.music.play()\n",
    "            while(pygame.mixer.music.get_busy()):\n",
    "                ret, frame = cap.read()\n",
    "                landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee,l_knee2ankle,r_knee2ankle=mediapipe_detection(frame, pose)\n",
    "\n",
    "                color=(0,0,255)\n",
    "                try:\n",
    "                        cv2.putText(output_image,str(r_elbow),\n",
    "                                (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                        cv2.putText(output_image,str(r_shoulder),\n",
    "                                (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                        cv2.putText(output_image,str(r_hip),\n",
    "                                (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                        cv2.putText(output_image,str(r_knee),\n",
    "                                (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "                except:\n",
    "                    pass\n",
    "                cv2.putText(output_image,str(mp3name),(20,25),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA,)\n",
    "                # 顯示影像\n",
    "                cv2.imshow('OpenCV Feed', output_image)\n",
    "\n",
    "                # 如果按下 q 鍵，就停止處理影像\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    pygame.mixer.music.stop()\n",
    "                    # cv2.destroyAllWindows()    \n",
    "                    break\n",
    "                # 釋放資源\n",
    "\n",
    "            # 停止播放音樂\n",
    "            pygame.mixer.music.stop()\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 2 前彎向下\n",
    "def pose2(cap,x):\n",
    "    lastTime1 = 0\n",
    "    lastTime2 = 0\n",
    "    count=0\n",
    "    # cap = cv2.VideoCapture(cap_name)  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        while (cap.isOpened()):\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee,l_knee2ankle,r_knee2ankle=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA =l_hip>60 or r_hip>60\n",
    "            condB = l_knee<150 or r_knee<150\n",
    "                \n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'upper body close to thigh'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'upper body close to thigh'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"上身貼近大腿\",'zh-tw')\n",
    "                lastTime1 = time()\n",
    "                if(x==1):\n",
    "                    data = {'shoulder': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                count=count+1\n",
    "                print (count)\n",
    "                if (count>5):\n",
    "                    speak(\"那我們再聽一次\",'zh-tw')\n",
    "                    while mixer.music.get_busy() == True:\n",
    "                        continue\n",
    "                    return count\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'keep your legs straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'keep your legs straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"雙腿盡量伸直\",'zh-tw')\n",
    "                    lastTime2 = time() \n",
    "                    if(x==1):\n",
    "                        data = {'knee': '1'}\n",
    "                        response = requests.post(url, data=data)\n",
    "                        print(response.text)\n",
    "                    count=count+1\n",
    "                    print(count)\n",
    "                    if(count>5):\n",
    "                        speak(\"那我們再聽一次\",'zh-tw')\n",
    "                        while mixer.music.get_busy() == True:\n",
    "                            continue    \n",
    "                        return count            \n",
    "                else:\n",
    "                    speak(\"太棒了\",'zh-tw')\n",
    "                    while mixer.music.get_busy() == True:\n",
    "                        continue\n",
    "                    text2= ' success '\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    count=0\n",
    "                    return count\n",
    "            color=(0,0,255)\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_elbow),\n",
    "                            (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_shoulder),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_hip),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_knee),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # cv2.destroyAllWindows()\n",
    "                count=0    \n",
    "                return count\n",
    "            \n",
    "        # cap.release()\n",
    "        # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 3 背部向前延伸\n",
    "def pose3(cap,x):\n",
    "    lastTime1 = 0\n",
    "    lastTime2 = 0\n",
    "    count=0\n",
    "    # cap = cv2.VideoCapture(cap_name)  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        # speak(\"待會要做前彎向下,請注意平衡安全__  \",'zh-tw')   \n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee,l_knee2ankle,r_knee2ankle=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA =l_hip<50 or r_hip<50\n",
    "            condB = l_knee<160 or r_knee<160\n",
    "                \n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'back forward'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'back forward'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"上身抬高,背部向前延伸\",'zh-tw')\n",
    "                if(x==1):\n",
    "                    data = {'shoulder': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                lastTime1 = time()\n",
    "                count=count+1\n",
    "                print (count)\n",
    "                if(count>5):\n",
    "                    speak(\"那我們再聽一次\",'zh-tw')\n",
    "                    while mixer.music.get_busy() == True:\n",
    "                        continue\n",
    "                    return count\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'keep your legs straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'keep your legs straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"雙腿盡量伸直\",'zh-tw')\n",
    "                    lastTime2 = time() \n",
    "                    if(x==1):\n",
    "                        data = {'knee': '1'}\n",
    "                        response = requests.post(url, data=data)\n",
    "                        print(response.text)\n",
    "                    count=count+1\n",
    "                    print (count)\n",
    "                    if(count>5):\n",
    "                        speak(\"那我們再聽一次\",'zh-tw')\n",
    "                        while mixer.music.get_busy() == True:\n",
    "                            continue\n",
    "                        return count\n",
    "                    \n",
    "                else:\n",
    "                    speak(\"太棒了\",'zh-tw')\n",
    "                    while mixer.music.get_busy() == True:\n",
    "                        continue\n",
    "                    text2= ' success '\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    count=0\n",
    "                    return count \n",
    "            color=(0,0,255)\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_elbow),\n",
    "                            (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_shoulder),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_hip),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_knee),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # cv2.destroyAllWindows()\n",
    "                count=0    \n",
    "                return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 4-1 四足跪姿\n",
    "def pose4_1(cap,x):\n",
    "    lastTime1 = 0\n",
    "    count=0\n",
    "    # cap = cv2.VideoCapture(cap_name)  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee,l_knee2ankle,r_knee2ankle=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_knee2ankle>30 or r_knee2ankle>30\n",
    " \n",
    "                    \n",
    "            if condA and (time()-lastTime1)<6:\n",
    "                text1= 'legs back'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=6 :\n",
    "                text1= 'legs back'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"雙腳往後，膝蓋貼在地板上\",'zh-tw')\n",
    "                lastTime1 = time()\n",
    "                if(x==1):\n",
    "                    data = {'knee': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                count=count+1\n",
    "                print(count)\n",
    "                if(count>5):\n",
    "                    speak(\"那我們再聽一次\",'zh-tw')\n",
    "                    while mixer.music.get_busy() == True:\n",
    "                        continue\n",
    "                    return count\n",
    "            else:\n",
    "                text1= ' success '\n",
    "                cv2.putText(output_image, text1, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                \n",
    "                count=0\n",
    "                return count\n",
    "            \n",
    "\n",
    "            color=(0,0,255)\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_elbow),\n",
    "                            (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_shoulder),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_hip),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_knee),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # cv2.destroyAllWindows()\n",
    "                count=0\n",
    "                return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 4 下犬式\n",
    "def pose4_2(cap,x):\n",
    "    lastTime1 = 0\n",
    "    lastTime2 = 0\n",
    "    lastTime3 = 0\n",
    "    count=0\n",
    "    # cap = cv2.VideoCapture(cap_name)  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee,l_knee2ankle,r_knee2ankle=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_knee<145 or r_knee<145\n",
    "            condB = l_shoulder<145 or r_shoulder<145\n",
    "            condC = l_elbow<145 or r_elbow<145  \n",
    "                    \n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'legs straight'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'legs straight'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"雙腳伸直\",'zh-tw')\n",
    "                lastTime1 = time()\n",
    "                if(x==1):\n",
    "                    data = {'knee': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                count=count+1\n",
    "                print(count)\n",
    "                if(count>5):\n",
    "                    speak(\"那我們再聽一次\",'zh-tw')\n",
    "                    while mixer.music.get_busy() == True:\n",
    "                        continue\n",
    "                    return count\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<5 :\n",
    "                    text2= 'shoulder and back straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=5 :\n",
    "                    text2= 'shoulder and back straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"背部打直,背部與手臂成一直線\",'zh-tw')\n",
    "                    lastTime2 = time()\n",
    "                    if(x==1):\n",
    "                        data = {'shoulder': '1'}\n",
    "                        response = requests.post(url, data=data)\n",
    "                        print(response.text) \n",
    "                    count=count+1\n",
    "                    print(count)\n",
    "                    if(count>5):\n",
    "                        speak(\"那我們再聽一次\",'zh-tw')\n",
    "                        while mixer.music.get_busy() == True:\n",
    "                            continue\n",
    "                        return count\n",
    "                else:\n",
    "                    text2= ' '\n",
    "                    cv2.putText(output_image, text2, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    if condC and (time()-lastTime3)<4 :\n",
    "                        text3= 'elbows straight'\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    elif condC and (time()-lastTime3)>=4 :\n",
    "                        text3= 'elbows straight'\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        speak(\"雙手打直\",'zh-tw')\n",
    "                        lastTime3 = time() \n",
    "                        if(x==1):\n",
    "                            data = {'r_elbow': '1'}\n",
    "                            response = requests.post(url, data=data)\n",
    "                            print(response.text)\n",
    "                        count=count+1\n",
    "                        print(count)\n",
    "                        if(count>5):\n",
    "                            speak(\"那我們再聽一次\",'zh-tw')\n",
    "                            while mixer.music.get_busy() == True:\n",
    "                                continue\n",
    "                            return count\n",
    "                    else:\n",
    "                        text3= ' success '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        speak(\"太棒了\",'zh-tw')\n",
    "                        while mixer.music.get_busy() == True:\n",
    "                            continue\n",
    "                        count=0\n",
    "                        return count\n",
    "\n",
    "            color=(0,0,255)\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_elbow),\n",
    "                            (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_shoulder),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_hip),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_knee),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # cv2.destroyAllWindows()\n",
    "                count=0\n",
    "                return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 5 平板式\n",
    "def pose5(cap,x):\n",
    "    lastTime1 = 0\n",
    "    lastTime2 = 0\n",
    "    lastTime3 = 0\n",
    "    count=0\n",
    "    # cap = cv2.VideoCapture(cap_name)  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee,l_knee2ankle,r_knee2ankle=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_shoulder>100 or r_shoulder>100\n",
    "            condB = l_knee <150 or r_knee <150  \n",
    "            condC = l_hip <150 or r_hip <150  \n",
    "\n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'Shoulders come directly over wrists'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'Shoulders come directly over wrists'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"肩膀來到手腕的正上方\",'zh-tw')\n",
    "                lastTime1 = time()\n",
    "                if(x==1):\n",
    "                    data = {'shoulder': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                count=count+1\n",
    "                print(count)\n",
    "                if(count>5):\n",
    "                    speak(\"那我們再聽一次\",'zh-tw')\n",
    "                    while mixer.music.get_busy() == True:\n",
    "                        continue\n",
    "                    return count\n",
    "            else:    \n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'hip and leg straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'ship and leg straight'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"膝蓋打直\",'zh-tw')\n",
    "                    lastTime2 = time()\n",
    "                    if(x==1):\n",
    "                        data = {'knee': '1'}\n",
    "                        response = requests.post(url, data=data)\n",
    "                        print(response.text)\n",
    "                    count=count+1\n",
    "                    print(count)\n",
    "                    if(count>5):\n",
    "                        speak(\"那我們再聽一次\",'zh-tw')\n",
    "                        while mixer.music.get_busy() == True:\n",
    "                            continue\n",
    "                        return count\n",
    "                else:\n",
    "                    text2= ' '\n",
    "                    cv2.putText(output_image, text2, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    if condC and (time()-lastTime3)<4 :\n",
    "                        text3= 'hip straight'\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    elif condC and (time()-lastTime3)>=4 :\n",
    "                        text3= 'hip straight'\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        speak(\"臀部打平\",'zh-tw')\n",
    "                        lastTime3 = time()\n",
    "                        if(x==1):\n",
    "                            data = {'hips': '1'}\n",
    "                            response = requests.post(url, data=data)\n",
    "                            print(response.text) \n",
    "                        count=count+1\n",
    "                        print(count)\n",
    "                        if(count>5):\n",
    "                            speak(\"那我們再聽一次\",'zh-tw')\n",
    "                            while mixer.music.get_busy() == True:\n",
    "                                continue\n",
    "                            return count\n",
    "                    else:\n",
    "                        text2= ' success '\n",
    "                        cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        speak(\"太棒了\",'zh-tw')\n",
    "                        while mixer.music.get_busy() == True:\n",
    "                            continue\n",
    "                        count=0\n",
    "                        return count\n",
    "\n",
    "            color=(0,0,255)\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_elbow),\n",
    "                            (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_shoulder),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_hip),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_knee),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # cv2.destroyAllWindows()    \n",
    "                count=0    \n",
    "                return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose 6 眼鏡蛇式\n",
    "def pose6(cap,x):\n",
    "    lastTime1 = 0\n",
    "    lastTime2 = 0\n",
    "    lastTime3 = 0\n",
    "    count=0\n",
    "    # cap = cv2.VideoCapture(cap_name)  # 開啟鏡頭\n",
    "    with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            landmarks,output_image,l_elbow,r_elbow,l_shoulder,r_shoulder,l_hip,r_hip,l_knee,r_knee,l_knee2ankle,r_knee2ankle=mediapipe_detection(frame, pose)\n",
    "\n",
    "            condA = l_knee<160 or r_knee<160\n",
    "            condB = l_hip >150 or r_hip >150\n",
    "            condC = l_shoulder>50 or r_shoulder>50\n",
    "\n",
    "            if condA and (time()-lastTime1)<4:\n",
    "                text1= 'straight the legs'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "            elif condA and (time()-lastTime1)>=4 :\n",
    "                text1= 'straight the legs'\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                speak(\"雙腿伸直\",'zh-tw')\n",
    "                lastTime1=time()\n",
    "                if(x==1):\n",
    "                    data = {'knee': '1'}\n",
    "                    response = requests.post(url, data=data)\n",
    "                    print(response.text)\n",
    "                count=count+1\n",
    "                print (count)\n",
    "                if(count>5):\n",
    "                    speak(\"那我們再聽一次\",'zh-tw')\n",
    "                    while mixer.music.get_busy() == True:\n",
    "                        continue\n",
    "                    return count\n",
    "            else:\n",
    "                text1= ' '\n",
    "                cv2.putText(output_image, text1, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                if condB and (time()-lastTime2)<4 :\n",
    "                    text2= 'low-body on the floor'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                elif condB and (time()-lastTime2)>=4 :\n",
    "                    text2= 'low-body on the floor'\n",
    "                    cv2.putText(output_image, text2, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    speak(\"下半身貼好在地板上\",'zh-tw')\n",
    "                    lastTime2 = time() \n",
    "                    if(x==1):\n",
    "                        data = {'hips': '1'}\n",
    "                        response = requests.post(url, data=data)\n",
    "                        print(response.text) \n",
    "                    count=count+1\n",
    "                    print (count)\n",
    "                    if(count>5):\n",
    "                        speak(\"那我們再聽一次\",'zh-tw')\n",
    "                        while mixer.music.get_busy() == True:\n",
    "                            continue\n",
    "                        return count \n",
    "                else:    \n",
    "                    text2= ' '\n",
    "                    cv2.putText(output_image, text2, (30, 30),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    if condC and (time()-lastTime3)<4 :\n",
    "                        text3= 'upper body improvement '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                    elif condC and (time()-lastTime3)>=4 :\n",
    "                        text3= 'upper body improvement '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        speak(\"上半身提高\",'zh-tw')\n",
    "                        lastTime3 = time() \n",
    "                        if(x==1):\n",
    "                            data = {'shoulder': '1'}\n",
    "                            response = requests.post(url, data=data)\n",
    "                            print(response.text) \n",
    "                        count=count+1\n",
    "                        print (count)\n",
    "                        if(count>5):\n",
    "                            return count\n",
    "                    else:\n",
    "                        text3= ' success '\n",
    "                        cv2.putText(output_image, text3, (30, 60),cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)\n",
    "                        speak(\"太棒了\",'zh-tw')\n",
    "                        while mixer.music.get_busy() == True:\n",
    "                            continue\n",
    "                        count=0\n",
    "                        return count\n",
    "            color=(0,0,255)\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_elbow),\n",
    "                            (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_shoulder),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_hip),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            try:\n",
    "                cv2.putText(output_image,str(r_knee),\n",
    "                        (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][0],landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value][1],),cv2.FONT_HERSHEY_SIMPLEX,1,color,2,cv2.LINE_AA,)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            cv2.imshow('OpenCV Feed', output_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # cv2.destroyAllWindows()    \n",
    "                count=0\n",
    "                return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vibration(x):\n",
    "    try:\n",
    "            if(x==1):\n",
    "                data = {'elbows': '1'}\n",
    "                response = requests.post(url, data=data)\n",
    "                print(response.text)\n",
    "            elif(x==2):\n",
    "                data = {'shoulder': '1'}\n",
    "                response = requests.post(url, data=data)\n",
    "                print(response.text)\n",
    "            elif(x==3):\n",
    "                data = {'hips': '1'}\n",
    "                response = requests.post(url, data=data)\n",
    "                print(response.text)\n",
    "            elif(x==4):\n",
    "                data = {'knee': '1'}\n",
    "                response = requests.post(url, data=data)\n",
    "                print(response.text)\n",
    "    except:\n",
    "         pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(a):\n",
    "    if(a==1):\n",
    "        speak(\"前彎向下介紹\",'zh-tw')\n",
    "        while mixer.music.get_busy() == True:\n",
    "            continue\n",
    "        touch(\"pose2_cut.mp3\")\n",
    "    elif(a==2):\n",
    "        speak(\"下犬式介紹\",'zh-tw')\n",
    "        while mixer.music.get_busy() == True:\n",
    "            continue\n",
    "        touch(\"pose4_cut.mp3\")\n",
    "    elif(a==3):\n",
    "        speak(\"平板式介紹\",'zh-tw')\n",
    "        while mixer.music.get_busy() == True:\n",
    "            continue\n",
    "        touch(\"pose5_cut.mp3\")\n",
    "    elif(a==4):\n",
    "        speak(\"眼鏡蛇式介紹\",'zh-tw')\n",
    "        while mixer.music.get_busy() == True:\n",
    "            continue\n",
    "        touch(\"pose6_cut.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=test_http()\n",
    "if x==1:\n",
    "    test_vibration(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre(1) #1前彎#2下犬#3平板#4眼鏡蛇\n",
    "pre(2)\n",
    "pre(3)\n",
    "pre(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"yoga-1.mp4\") # 開啟鏡頭\n",
    "x=test_http() # 測試http狀態\n",
    "\n",
    "main(\"part1.mp3\",cap)\n",
    "count=10\n",
    "while(count>5):\n",
    "    main(\"part2.mp3\",cap) \n",
    "    count=pose2(cap,x)\n",
    "    if count==0:\n",
    "        break\n",
    "count=10\n",
    "while(count>5):\n",
    "    main(\"part3.mp3\",cap)\n",
    "    count=pose3(cap,x)\n",
    "    if count==0:\n",
    "        break\n",
    "count=10\n",
    "while(count>5):\n",
    "    main(\"part4-1.mp3\",cap)\n",
    "    count=pose4_1(cap,x)\n",
    "    if count==0:\n",
    "        break\n",
    "count=10\n",
    "while(count>5):\n",
    "    main(\"part4-2.mp3\",cap)\n",
    "    count=pose4_2(cap,x)\n",
    "    if count==0:\n",
    "        break\n",
    "count=10\n",
    "while(count>5):\n",
    "    main(\"part5.mp3\",cap)\n",
    "    count=pose5(cap,x)\n",
    "    if count==0:\n",
    "        break\n",
    "count=10\n",
    "while(count>5):\n",
    "    main(\"part6.mp3\",cap)\n",
    "    count=pose6(cap,x)\n",
    "    if count==0:\n",
    "        break\n",
    "count=10\n",
    "while(count>5):\n",
    "    main(\"part7.mp3\",cap)\n",
    "    count=pose4_2(cap,x)\n",
    "    if count==0:\n",
    "        break\n",
    "count=10\n",
    "while(count>5):\n",
    "    main(\"part8.mp3\",cap)\n",
    "    count=pose2(cap,x)\n",
    "    if count==0:\n",
    "        break\n",
    "main(\"part9.mp3\",cap)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82a87e48d8ad47d54d8434aa198ab5f7e9ca4eddc7a6e80c14d429723cf302a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
