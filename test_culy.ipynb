{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.0.22, Python 3.8.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "from pygame import mixer\n",
    "import tempfile\n",
    "from gtts import gTTS\n",
    "import requests\n",
    "import pygame\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算角度的副函式\n",
    "def calculatexang(landmark1, landmark2):\n",
    "    # 獲取所需座標\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "\n",
    "    angle=math.floor(math.degrees(math.atan2(y1 - y2, x1 - x2)))\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    if angle>180:\n",
    "        angle=360-angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) \n",
    "    height, width, _ = image.shape\n",
    "    landmarks = []\n",
    "    if results.pose_landmarks:\n",
    "            # 畫關鍵點在圖片上\n",
    "        mp_drawing.draw_landmarks(image=image, landmark_list=results.pose_landmarks,\n",
    "                    connections=mp_pose.POSE_CONNECTIONS)\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "        # 將關鍵點加進list內.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                    (landmark.z * width)))    \n",
    "    \n",
    "    try:\n",
    "        # 取得左臀、左膝蓋和左腳踝之間的角度。# 23 25 27\n",
    "        l_knee2ankle = calculatexang( landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    except:\n",
    "        l_knee2ankle=0        \n",
    "    try:\n",
    "        # 取得右臀、右膝蓋和右腳踝之間的角度。# 24 26 28 \n",
    "        r_knee2ankle = calculatexang( landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    except:\n",
    "        r_knee2ankle=0\n",
    "    return landmarks,image,l_knee2ankle,r_knee2ankle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94, 96]\n",
      "[95, 95]\n",
      "[95, 95]\n",
      "[86, 85]\n",
      "[76, 76]\n",
      "[98, 98]\n",
      "[41, 80]\n",
      "[0, 2]\n",
      "[34, 34]\n"
     ]
    }
   ],
   "source": [
    "lastTime1 = 0\n",
    "cap = cv2.VideoCapture(\"yoga-1.mp4\")\n",
    "with mp_pose.Pose(static_image_mode=False, \n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5, \n",
    "                    model_complexity=0)as pose:\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "        landmarks,output_image,l_knee2ankle,r_knee2ankle=mediapipe_detection(frame, pose)\n",
    "        if (time()-lastTime1)>4:\n",
    "            print([l_knee2ankle,r_knee2ankle])\n",
    "            lastTime1=time()\n",
    "        \n",
    "        cv2.imshow('OpenCV Feed', output_image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "        # cap.release()\n",
    "        # cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
